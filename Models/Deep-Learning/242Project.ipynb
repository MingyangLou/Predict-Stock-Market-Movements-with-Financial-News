{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "242Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9hmcZ5YXDUg",
        "colab_type": "code",
        "outputId": "db6612ea-dadb-484a-e8af-d686a95374b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir('/content/gdrive/My Drive/242 Group Project/data')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL64ywEgn_SG",
        "colab_type": "code",
        "outputId": "20d77e36-aee8-4838-edd1-6be5f1743594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# Load pakages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "from datetime import datetime\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import median_absolute_error as mae\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import accuracy_score as acc\n",
        "import matplotlib.pyplot as plt\n",
        "# NLP\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Preprocess functions in keras\n",
        "from keras.preprocessing.text import one_hot, Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "# Models in keras\n",
        "from keras.models import Sequential\n",
        "from keras import initializers\n",
        "from keras.layers import Dropout, Activation,Embedding,CuDNNGRU,Bidirectional,Convolution1D, MaxPooling1D, Input, Dense, BatchNormalization\n",
        "from keras.layers.recurrent import LSTM, GRU\n",
        "from keras.layers import concatenate, Conv1D, CuDNNLSTM\n",
        "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, SpatialDropout1D\n",
        "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.models import Model, load_model\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras import regularizers\n",
        "from keras.layers.core import Reshape, Flatten\n",
        "from keras.utils import to_categorical\n",
        "#Word2Vec\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_BeVrH0oLP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sp500 = pd.read_csv('SP_500_label.csv')\n",
        "Corpus = pd.read_csv('corpus.csv')[['datetime','text_final']]\n",
        "Corpus_date = pd.read_csv('corpus_date.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxYTsc7nQjRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tech_indicators = pd.read_csv('tech_indicators_update.csv')\n",
        "tech_indicators['Date'] = tech_indicators['Date'].apply(lambda x:datetime.strptime(x,'%m/%d/%y'))\n",
        "tech_indicators = tech_indicators[tech_indicators.Date.isin(sp500.Date)]\n",
        "tech_indicators = tech_indicators.reset_index(drop = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1QDWHdwQ-gB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tech_indicators1 = tech_indicators[tech_indicators.columns[~tech_indicators.columns.isin(['Date'])]]\n",
        "tech_train = tech_indicators1.iloc[:1309,]\n",
        "tech_test = tech_indicators1.iloc[1309:,]\n",
        "tech_test = tech_test.reset_index(drop = True)\n",
        "tech_train = np.array(tech_train)\n",
        "tech_test = np.array(tech_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbAqamX5p7Eb",
        "colab_type": "code",
        "outputId": "fc2e93e3-d66c-4b65-cf27-78e1c57edc52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "t = Tokenizer()\n",
        "t.fit_on_texts(Corpus_date['docs'])\n",
        "\n",
        "# Take a look at our tokens\n",
        "print(list(t.word_index.items())[-1])\n",
        "print(len(list(t.word_index.items())))\n",
        "\n",
        "vocab_size = len(t.word_index) + 1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('allegiant', 16705)\n",
            "16705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfYeZ8tJsS0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_docs = t.texts_to_sequences(Corpus_date['docs'])\n",
        "# pad documents to a max length\n",
        "max_length = max(len(x) for x in encoded_docs)\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "843cFaDFvBFK",
        "colab_type": "code",
        "outputId": "a7565454-908d-4430-b037-850f7f32dcf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "embeddings_index = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23UmlZ_frHWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 300\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09hUi8GSvhc3",
        "colab_type": "code",
        "outputId": "9cdd1efc-f6db-471e-c15a-1d95adf001e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "for word, i in t.word_index.items():\n",
        "    if word in embeddings_index:\n",
        "        embedding_matrix[i] = embeddings_index[word]\n",
        "    else:   \n",
        "        embedding_matrix[i] = np.random.normal(0,np.sqrt(0.25),embedding_dim)\n",
        "    if i%5000 ==0:\n",
        "        print(i)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n",
            "10000\n",
            "15000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qkc-VmlKbAVH",
        "colab_type": "code",
        "outputId": "e1948939-6bd3-4deb-f08a-153751b0d764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "x_train, x_test = padded_docs[:1309],padded_docs[1309:]\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohe = OneHotEncoder(sparse=False)\n",
        "label = sp500['label']\n",
        "y_ohe = ohe.fit_transform(label.values.reshape(-1, 1))\n",
        "# type: np.ndarray\n",
        "y_train, y_test = y_ohe[:1309],y_ohe[1309:]\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOKBvWNBc7-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WBEAAOsdntC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = \"best_model.hdf5\"\n",
        "check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
        "                              save_best_only = True, mode = \"min\")\n",
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 3)\n",
        "tech_num = len(tech_indicators1.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPIJP4nneLnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(lr = 0.0, lr_d = 0.0, units = 0, dr = 0.0):\n",
        "    inp = Input(shape = (max_length,))\n",
        "    x = Embedding(vocab_size, embedding_dim, weights = [embedding_matrix], trainable = False)(inp)\n",
        "    x1 = SpatialDropout1D(dr)(x)\n",
        "\n",
        "    x_gru = Bidirectional(CuDNNGRU(units, return_sequences = True))(x1)\n",
        "    x1 = Conv1D(32, kernel_size=3, padding='valid', kernel_initializer='he_uniform')(x_gru)\n",
        "    avg_pool1_gru = GlobalAveragePooling1D()(x1)\n",
        "    max_pool1_gru = GlobalMaxPooling1D()(x1)\n",
        "    \n",
        "    x3 = Conv1D(32, kernel_size=2, padding='valid', kernel_initializer='he_uniform')(x_gru)\n",
        "    avg_pool3_gru = GlobalAveragePooling1D()(x3)\n",
        "    max_pool3_gru = GlobalMaxPooling1D()(x3)\n",
        "    \n",
        "    x_lstm = Bidirectional(CuDNNLSTM(units, return_sequences = True))(x1)\n",
        "    x1 = Conv1D(32, kernel_size=3, padding='valid', kernel_initializer='he_uniform')(x_lstm)\n",
        "    avg_pool1_lstm = GlobalAveragePooling1D()(x1)\n",
        "    max_pool1_lstm = GlobalMaxPooling1D()(x1)\n",
        "    \n",
        "    x3 = Conv1D(32, kernel_size=2, padding='valid', kernel_initializer='he_uniform')(x_lstm)\n",
        "    avg_pool3_lstm = GlobalAveragePooling1D()(x3)\n",
        "    max_pool3_lstm = GlobalMaxPooling1D()(x3)\n",
        "    \n",
        "    \n",
        "    x = concatenate([avg_pool1_gru, max_pool1_gru, avg_pool3_gru, max_pool3_gru,\n",
        "                    avg_pool1_lstm, max_pool1_lstm, avg_pool3_lstm, max_pool3_lstm])\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.2)(Dense(128,activation='relu') (x))\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.2)(Dense(100,activation='relu') (x))\n",
        "    x = Dense(2, activation = \"softmax\")(x)\n",
        "\n",
        "    model = Model(inputs = inp, outputs = x)\n",
        "    #sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n",
        "    history = model.fit(x_train, y_train, batch_size = 128, epochs = 15, validation_split=0.1, \n",
        "                        verbose = 1, callbacks = [check_point, early_stop])\n",
        "    model = load_model(file_path)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igameaMbeSYO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ac7ebf42-8ae8-4f91-9252-24ce00b1b6c0"
      },
      "source": [
        "model = build_model(lr = 1e-4, lr_d = 0, units = 128, dr = 0.5)\n",
        "pred = model.predict(x_test, batch_size = 1024)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1178 samples, validate on 131 samples\n",
            "Epoch 1/15\n",
            "1178/1178 [==============================] - 25s 21ms/step - loss: 0.8904 - acc: 0.5204 - val_loss: 0.8716 - val_acc: 0.4580\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.68001\n",
            "Epoch 2/15\n",
            "1178/1178 [==============================] - 2s 2ms/step - loss: 0.8828 - acc: 0.5161 - val_loss: 0.8803 - val_acc: 0.4656\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.68001\n",
            "Epoch 3/15\n",
            "1178/1178 [==============================] - 2s 2ms/step - loss: 0.8426 - acc: 0.5280 - val_loss: 0.8496 - val_acc: 0.4504\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.68001\n",
            "Epoch 4/15\n",
            "1178/1178 [==============================] - 2s 2ms/step - loss: 0.8982 - acc: 0.5025 - val_loss: 0.8123 - val_acc: 0.4580\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.68001\n",
            "Epoch 5/15\n",
            "1178/1178 [==============================] - 2s 2ms/step - loss: 0.8477 - acc: 0.5246 - val_loss: 0.7875 - val_acc: 0.4656\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.68001\n",
            "Epoch 6/15\n",
            "1178/1178 [==============================] - 2s 2ms/step - loss: 0.8547 - acc: 0.5051 - val_loss: 0.7724 - val_acc: 0.4580\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.68001\n",
            "Epoch 7/15\n",
            "1178/1178 [==============================] - 2s 2ms/step - loss: 0.8255 - acc: 0.5535 - val_loss: 0.7691 - val_acc: 0.4580\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.68001\n",
            "Epoch 8/15\n",
            "1178/1178 [==============================] - 2s 2ms/step - loss: 0.8349 - acc: 0.5170 - val_loss: 0.7718 - val_acc: 0.4885\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.68001\n",
            "Epoch 9/15\n",
            "1178/1178 [==============================] - 2s 2ms/step - loss: 0.8349 - acc: 0.5272 - val_loss: 0.7657 - val_acc: 0.4885\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.68001\n",
            "Epoch 10/15\n",
            "1178/1178 [==============================] - 2s 2ms/step - loss: 0.7934 - acc: 0.5382 - val_loss: 0.7678 - val_acc: 0.4733\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.68001\n",
            "Epoch 11/15\n",
            "1178/1178 [==============================] - 2s 2ms/step - loss: 0.7916 - acc: 0.5348 - val_loss: 0.7634 - val_acc: 0.4885\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.68001\n",
            "Epoch 12/15\n",
            "1178/1178 [==============================] - 2s 2ms/step - loss: 0.8243 - acc: 0.5272 - val_loss: 0.7558 - val_acc: 0.4962\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.68001\n",
            "Epoch 13/15\n",
            "1178/1178 [==============================] - 2s 2ms/step - loss: 0.8119 - acc: 0.5340 - val_loss: 0.7434 - val_acc: 0.4962\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.68001\n",
            "Epoch 14/15\n",
            "1178/1178 [==============================] - 2s 2ms/step - loss: 0.8305 - acc: 0.5195 - val_loss: 0.7402 - val_acc: 0.4885\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.68001\n",
            "Epoch 15/15\n",
            "1178/1178 [==============================] - 2s 2ms/step - loss: 0.8172 - acc: 0.5306 - val_loss: 0.7411 - val_acc: 0.5038\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.68001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asvgCm2ufc-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true = label[1309:].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5MqxicneRRZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e8db0946-dff8-472c-9df5-0b829382bb51"
      },
      "source": [
        "(eval_loss, eval_accuracy) = model.evaluate(x_test, y_test)\n",
        "eval_accuracy"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "472/472 [==============================] - 8s 17ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.49364406678636197"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnO_aq24fdaC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "13641de0-9b65-420a-f83c-44433519a981"
      },
      "source": [
        "y_pred = np.round(np.argmax(pred, axis=1)).astype(int)\n",
        "y_pred = pd.DataFrame(y_pred,columns=['NN'])\n",
        "y_pred.head()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   NN\n",
              "0   0\n",
              "1   0\n",
              "2   0\n",
              "3   0\n",
              "4   1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3eGZhBNfdhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred.to_csv('Neural_Networks_pred.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}